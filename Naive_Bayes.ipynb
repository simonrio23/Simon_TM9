{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simonrio23/Simon_TM9/blob/main/Naive_Bayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-74IodEqDyf"
      },
      "source": [
        "Naive-Bayes Algorithm\n",
        "=====================\n",
        "***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klmxuFsAqDyk"
      },
      "source": [
        "What Is It?\n",
        "-----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "su7bXYG8qDyl"
      },
      "source": [
        "The Naive-Bayes algorithm is an intuitive approach to making predictions based on prior beliefs or probabilities. Quoting Jason Brownlee, \"it is the supervised learning approach you would come up with if you wanted to model a predictive modeling problem probabilistically\".\n",
        "\n",
        "Let's dive into the mathematics. We start off with a belief or a *prior probability* of event $A$. This is denoted as $P(A)$. Now, everything seems to be going well until we're hit with some new evidence $X$, which implies something that affects the probability of our belief. As much as we'd like to, we can't simply ignore $X$ and go home. Instead, given evidence $X$, we must calculate a new value for event $A$ called the *posterior probability*. This is denoted as $P(A | X)$. Finally, for the sake of completion, $P(X | A)$ is the probability of observing evidence $X$ for event $A$ and $P(X)$ is the untouched probability of observing evidence $X$.\n",
        "\n",
        "\\begin{align}\n",
        " P( A | X ) = & \\frac{ P(X | A) P(A) } {P(X) } \\\\\\\\[5pt]\n",
        "\\end{align}\n",
        "\n",
        "You're probably wondering what makes this algorithm *naive*. Well, it's due to the underlying assumption that the probability of event $A$ given any evidence $X_n$ is totally independent of each other. This simplifies a lot of things and explains its popularity in many fields.\n",
        "\n",
        "The content of this notebook uses Python to classify whether a patient is diagnosed with diabetes given a set of attributes. The data set is called the \"Pima Indians Diabetes Data Set\" provided by the National Institute of Diabetes and Digestive and Kidney Diseases. The target accuracy to indicate the algorithm's credibility is between 70% - 76%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjQwI6vxqDym"
      },
      "source": [
        "Data Loading and Formatting\n",
        "-------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KV7GEbVAqDym"
      },
      "source": [
        "The data set is given as a `csv` file, which requires parsing and partitioning to form a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount ('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVWuhZeMzJ8l",
        "outputId": "4f31ff69-515a-45e9-8ea0-e56d3e02ab26"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "def load_csv(file):\n",
        "    with open(file, 'r') as csvfile:\n",
        "        lines = csv.reader(csvfile)\n",
        "        dataset = list(lines)\n",
        "        for i in range(len(dataset)):\n",
        "            dataset[i] = [float(x) for x in dataset[i]]\n",
        "    return dataset\n",
        "\n",
        "file = ('/content/drive/MyDrive/SimonRioArwam/TM9/Dataset/pima-indians-diabetes.data.csv')  # Sesuaikan dengan path file Anda\n",
        "dataset = load_csv(file)\n",
        "print('Loaded data from {0} with {1} rows'.format(file, len(dataset)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vW4oKu0xzorp",
        "outputId": "5b136103-585b-426b-e7d7-d0bb3b8a4bcf"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded data from /content/drive/MyDrive/SimonRioArwam/TM9/Dataset/pima-indians-diabetes.data.csv with 768 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randrange\n",
        "\n",
        "def partition_data(dataset, ratio):\n",
        "    train_size = int(len(dataset) * ratio)\n",
        "    test_set = list(dataset)\n",
        "    train_set = []\n",
        "\n",
        "    while len(train_set) < train_size:\n",
        "        index = randrange(len(test_set))\n",
        "        train_set.append(test_set.pop(index))\n",
        "\n",
        "    return [train_set, test_set]\n",
        "\n",
        "train_set, test_set = partition_data(dataset, 0.67)\n",
        "print('Split total data ({0} rows) into training set ({1} rows) and testing set ({2} rows)'.format(len(dataset), len(train_set), len(test_set)))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DOXjYUH1yNI",
        "outputId": "7d2104bd-74ce-42d9-baaf-a4707cee47af"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split total data (768 rows) into training set (514 rows) and testing set (254 rows)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def group_by_class(dataset):\n",
        "    klass_map = {}\n",
        "    for el in dataset:\n",
        "        klass = int(el[-1])\n",
        "        if klass not in klass_map:\n",
        "            klass_map[klass] = []\n",
        "        klass_map[klass].append(el[:-1])\n",
        "    return klass_map\n",
        "\n",
        "classified_set = group_by_class(train_set)\n",
        "\n",
        "for klass, data_points in classified_set.items():\n",
        "    print('Class {0} contains {1} data points'.format(klass, len(data_points)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6IPiRSD2emn",
        "outputId": "fc77e863-235e-4eb6-8a31-0751169d9064"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 contains 336 data points\n",
            "Class 1 contains 178 data points\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def mean(n):\n",
        "    return sum(n) / float(len(n))\n",
        "\n",
        "def stdev(n):\n",
        "    average = mean(n)\n",
        "    return math.sqrt(sum([pow(x - average, 2) for x in n]) / float(len(n) - 1))"
      ],
      "metadata": {
        "id": "JHGjNn822tCE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing as mp\n",
        "\n",
        "def format_calc(t):\n",
        "    return (mean(t), stdev(t))\n",
        "\n",
        "def prepare_data(dataset):\n",
        "    pool = mp.Pool(mp.cpu_count())\n",
        "    summary = {}\n",
        "    for klass, data_points in dataset.items():  # Menggunakan items() alih-alih iteritems()\n",
        "        summary[klass] = pool.map(format_calc, zip(*data_points))\n",
        "    pool.close()\n",
        "    pool.join()\n",
        "    return summary\n",
        "\n",
        "summary_set = prepare_data(classified_set)\n",
        "\n",
        "for klass, tupl in summary_set.items():  # Menggunakan items() alih-alih iteritems()\n",
        "    print('Class {0} contains {1} tuples'.format(klass, len(tupl)))  # Memindahkan metode format() ke dalam tanda kurung print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8r_lT4H22aV",
        "outputId": "455a5a7b-7cba-4db3-a5c4-b769f1c0b8ac"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 contains 8 tuples\n",
            "Class 1 contains 8 tuples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def gauss(x, mean, stdev):\n",
        "    ex = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
        "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * ex"
      ],
      "metadata": {
        "id": "oe8qPhnU3Ax7"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(summary_set, data_point):\n",
        "    probabilities = {}\n",
        "    for klass, summary in summary_set.iteritems():\n",
        "        probabilities[klass] = 1\n",
        "        for i in xrange(len(summary)):\n",
        "            mean, stdev = summary[i]\n",
        "            probabilities[klass] *= gauss(data_point[i], mean, stdev)\n",
        "    return max(probabilities.iterkeys(), key=(lambda key: probabilities[key]))"
      ],
      "metadata": {
        "id": "EkCA5y0d3I-R"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = get_accuracy(summary_set, test_set)\n",
        "\n",
        "print('The_Naive-Bayes_Model_yields {0}% accuracy'.format(round(accuracy, 2)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "5XfdG2oV3Qjy",
        "outputId": "03f9cb80-706f-49ce-9759-d3f24884287a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'dict' object has no attribute 'iteritems'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-91e23073dbe2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The_Naive-Bayes_Model_yields {0}% accuracy'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-66-656492720bd2>\u001b[0m in \u001b[0;36mget_accuracy\u001b[0;34m(summary_set, test_set)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mcorrect_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtest_point\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtest_point\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m             \u001b[0mcorrect_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcorrect_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-d6fdc256022b>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(summary_set, data_point)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_point\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msummary_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprobabilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mklass\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'iteritems'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}